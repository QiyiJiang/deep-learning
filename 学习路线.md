# MiniMind 系统化学习路线（最终版）

本路线融合多份学习计划，以 **AI 系统工程师** 的视角，带你系统地从"能跑通模型"进阶到"能改写算子、优化系统"。整个学习分为两大阶段：前 12 周主线（搭建从训练到部署的闭环）和后 12 周强化（深挖推理性能优化与工程落地）。每周包含明确的周目标、每日任务、以及交付物和验收标准，要求动手实践、记录分析、产出成果。请根据自身进度酌情调整，并坚持记录实验过程和思考，让学习成果可复现、可验证。

**学习原则**：产出驱动、循序渐进；每个阶段都聚焦"读懂代码→跑起来复现→改进验证"的闭环。

**验收方式**：所有改动都需要有统一的基准对比（训练：loss曲线/收敛速度/吞吐/显存；推理：首token延迟（TTFT）/TPS/显存；质量：困惑度PPL等）。

## 阶段一：12 周主线

### 已完成基础（来自 llm_study，可快进）

你已在 `llm_study` 中完成并跑通了：RoPE、参数量控制、预训练/SFT、AMP、日志、KV cache、checkpoint 等核心链路。因此，原路线中**第 1–4 周的“从 0 到跑通”内容对你来说主要是复习**，可以压缩为下面这份清单（不再展开 day-by-day）。

#### 复习清单（可选，半天～1 天）

- **环境与基线**：能复现 `trainer/train_pretrain.py` 一次训练与一次推理，记录 loss/lr/显存/吞吐。
- **静态结构与形状**：能在白板上讲清 MiniMind 的张量形状流（QKV 分头、attention mask、FFN），并知道哪些 reshape/transpose 可能触发拷贝。
- **数据与 mask**：能解释 ChatML 拼接、padding 与 `loss_mask/ignore_index` 的关系，知道预训练和 SFT 的 mask 差异。
- **数值稳定**：能解释 AMP + GradScaler、梯度裁剪、warmup；遇到 NaN/OOM 能快速定位。

#### 第 1–4 周“保留的唯一必要产出”

- 一份 `experiments/baseline_minimind.md`：只记录一次 MiniMind 基线训练/推理结果（命令、指标、截图/日志），作为后续优化的对照基准。

### 第 5 周：Triton 算子开发入门

**周目标**：使用 OpenAI Triton 开发自定义 CUDA Kernel，提升底层算子性能（例如 Norm 操作）。

#### Day 1: Triton 入门教程

- **操作**：阅读 Triton 官方教程（如 `02-fused-softmax`），理解 `@triton.jit` 的基本用法；练习使用 `tl.load` 和 `tl.store` 从显存读写数据。
- **分析**：了解 Triton 如何将批量张量计算映射到 GPU 上，以及 register 和并行概念。
- **产出**：Triton 教程学习笔记。

#### Day 2: 自定义 Kernel 准备

- **操作**：安装 Triton（`pip install triton`），阅读 PyTorch Triton 接口（`torch.ops.triton`）；准备将要优化的算子（如 RMSNorm）。
- **分析**：定位 RMSNorm 原生实现（涉及 `pow`, `mean`, `rsqrt`, `mul` 等操作），评估其性能瓶颈（多次显存读写）。
- **产出**：算子性能分析报告。

#### Day 3: 编写 Triton RMSNorm Kernel

- **操作**：创建 `rms_norm_triton.py`，使用 Triton 编写一个单行数据的 RMSNorm Kernel：先 `tl.load` 一行数据到寄存器，计算平方和、均方根并应用归一化，最后 `tl.store` 回显存。
- **分析**：确保理解每一步骤的内存访问；考虑使用 `BLOCK_SIZE` 来划分线程块。
- **产出**：初步的 Triton RMSNorm 代码。

#### Day 4: Triton 算子测试

- **操作**：在 PyTorch 中封装 `torch.nn.Module` 调用 Triton Kernel，编写测试脚本；使用 `torch.allclose` 对比 Triton 实现与原生 RMSNorm 在各种输入下的数值一致性。
- **分析**：验证误差是否在容许范围（<1e-5）；检查不同 Batch, Seq 长度的正确性。
- **产出**：测试代码和结果日志。

#### Day 5: Triton 算子优化

- **操作**：优化 Kernel 性能，比如使用向量化（`tl.load` 连续内存）、减少 Python 循环；调整 `BLOCK_SIZE` 和 grid 配置确保利用率。
- **分析**：用 Triton 自带的 `triton.testing.do_bench` 简单对比小规模下速度，确认性能提升。
- **产出**：完整可复用的 `TritonRMSNorm` 类（含文档）和基准结果。

**交付物**：`TritonRMSNorm.py`（实现与封装）、测试报告（数值误差对比）、初步性能对比结果图。

**验收标准**：Triton 实现与原生实现误差 < 1e-5；Kernel 能运行并明显减少显存读写步骤。

### 第 6 周：算子集成与性能对比

**周目标**：将自定义 Triton 算子集成到 MiniMind 模型中，并进行性能基准测试；尝试算子融合（如 `torch.compile`）以进一步优化。

#### Day 1: Benchmark 脚本编写

- **操作**：编写基准测试脚本，使用 `triton.testing.do_bench` 或简单循环，测试不同输入尺寸下原生 RMSNorm 与 `TritonRMSNorm` 的执行时间。
- **分析**：记录在较大输入尺寸下的加速比，预期显存 IO 降低带来的 20%-50% 加速。
- **产出**：基准结果数据（表格或 CSV）。

#### Day 2: 算子替换集成

- **操作**：修改 MiniMind 的 `model.py`，在模型初始化时将原生 RMSNorm 替换为 `TritonRMSNorm`；确保模型前向调用生效。
- **分析**：检查模型可训练性，做一次前向测试确认输出正常。
- **产出**：修改后的模型代码片段（或新文件）。

#### Day 3: Triton 加速测试

- **操作**：在相同硬件上比较替换前后的训练/推理性能，重点记录吞吐（tokens/s）和显存峰值。
- **分析**：绘制柱状图对比，验证 Triton 算子带来的性能提升；总结优化效果。
- **产出**：Benchmark 对比图表。

#### Day 4: Torch.compile 算子融合

- **操作**：使用 PyTorch 2.0+ 提供的 `torch.compile` 编译 MiniMind 模型。
- **分析**：对比编译前后模型的推理延迟和使用 `nsys` 或 `torch.profiler` 的时间线图，找出哪些小算子被融合掉了。
- **产出**：nsys 时间线截屏或 Profiler 报告片段，标注被融合的 kernel。

#### Day 5: 集成与验证

- **操作**：将 Triton 算子和编译优化集成进主训练流程，确保可以端到端训练。
- **分析**：综合评估算子替换与融合带来的整体性能改进，更新实验记录。
- **产出**：最终的模型代码（包含 Triton 算子）和详细性能报告。

**交付物**：包含 Triton 算子实现的修改版 `model.py`，性能基准图表，融合前后 Timeline 报告。

**验收标准**：Triton 版本在大输入下显著加速（≥20%）；能够指认 nsys 报告中被融合的算子；模型功能不变且训练稳定。

### 第 7 周：KV Cache 优化与内存管理

**周目标**：优化推理阶段 KV Cache 的内存使用，减少显存碎片和重复申请，以提升推理效率。

#### Day 1: KV Cache 预分配思路

- **操作**：在推理代码中预分配一个足够大的缓存张量，比如 `cache = torch.zeros(batch, max_seq_len, num_heads, head_dim, device='cuda')`，并维护一个当前写入位置指针。
- **分析**：原有实现每步 `torch.cat` 新 KV 到列表会导致重复申请，预分配可以避免这个开销。
- **产出**：预分配 KV Cache 的代码草案。

#### Day 2: 实现预分配缓存

- **操作**：修改 MiniMind 的生成脚本，将每一步生成的 K/V 写入预分配张量（例如：`cache[:, pos, ...] = new_kv`），而不是使用列表 cat。
- **分析**：确保写入逻辑正确，前向推理结果与原实现一致。
- **产出**：更新后的推理脚本代码。

#### Day 3: 性能对比测试

- **操作**：分别运行原始 cat 模式和预分配模式，生成固定长度（如1000 tokens）的文本；记录两者的 TPS（每秒 Token 数）。
- **分析**：绘制对比图，量化改动后的性能提升比例。
- **产出**：TPS 对比数据和柱状图。

#### Day 4: 显存碎片分析

- **操作**：在运行中记录每一步显存分配情况（如使用前面 Week2 自定义的 `@track_memory` 装饰器），比较两种模式下显存增长曲线。
- **分析**：确认预分配模式有效降低了显存碎片和峰值增长速度。
- **产出**：显存使用曲线图。

#### Day 5: 总结与验证

- **操作**：综合分析性能与显存数据，对预分配策略的改进点进行文档总结。
- **产出**：KV Cache 优化报告，说明实现过程与效果。

**交付物**：修改后的推理脚本、对比测试结果（TPS 图表、显存曲线）、优化报告。

**验收标准**：预分配模式下 TPS 明显提升（常见可达 10%-30% 加速）；显存增长曲线更加平滑，验证减少了重复分配。

### 第 8 周：模型量化与导出

**周目标**：了解模型量化的影响，并掌握将模型导出为 ONNX 等格式的过程，为后续部署做准备。

#### Day 1: 伪量化实验

- **操作**：在 `model.py` 中线性层前加入简单的量化模拟，例如：`w_int8 = torch.round(w_fp16 / scale)`，以及反量化逻辑，将权重截断为低精度。
- **分析**：在不修改其他部分的情况下，用量化后的权重推理，观察困惑度（PPL）和输出文本质量的变化。
- **产出**：小型实验记录（量化 scale 变化及其影响）。

#### Day 2: 真实量化工具体验

- **操作**：尝试使用现有工具（如 bitsandbytes 的 8-bit 或 GPTQ 进行 4-bit 量化）对模型参数进行量化。
- **分析**：比较量化后与原模型在验证集或样例上的 PPL 差异；记录量化过程的步骤和问题。
- **产出**：量化结果对比表（FP16 vs INT8/INT4）。

#### Day 3: 导出 GGUF 与 Ollama 适配

- **操作**：使用 `llama.cpp` 的 `convert_hf_to_gguf.py` 将 MiniMind 导出为 `.gguf` 格式；编写 `Modelfile` 并通过 `ollama create` 导入。
- **分析**：理解 GGUF 格式对量化权重的支持；观察 Ollama 如何简化本地模型的加载与交互流程。
- **产出**：`minimind.gguf` 文件、`Modelfile` 及 Ollama 运行截图。

#### Day 4: ONNX 与端侧部署准备

- **操作**：使用 `torch.onnx.export` 将模型导出为 `.onnx` 文件；使用 Netron 观察计算图结构。
- **分析**：注意 Python 中的控制流如何被展开为静态图；评估 ONNX 模型在不同推理后端（如 ONNX Runtime）的通用性。
- **产出**：`minimind.onnx` 文件与 Netron 截图。

#### Day 5: 模型精度评估

- **操作**：对比量化后（使用 bitsandbytes、gptq）与导出模型在小型测试集上的输出差异。
- **分析**：分析量化带来的精度损失、ONNX 导出后的变更；准备模型压缩的对比报告。
- **产出**：量化与导出分析.md，包含 PPL、输出示例和性能数据。

**交付物**：`minimind.onnx` 文件，Netron 可视化截图，量化与导出对比报告。

**验收标准**：量化后模型仍能生成可读文本（接受一定 PPL 上升）；ONNX 模型正确导出且前向运行正常；报告中清楚说明了量化/导出对性能和精度的影响。

## 阶段二：12 周强化（每两周为一组）

### 第 13-14 周：推理性能剖析

**组目标**：使用 Profiler 和 Nsight Systems 等工具深入剖析推理过程中的瓶颈，为后续优化指明方向。

#### Week13 Day1: Torch Profiler 推理分析

- **操作**：对推理过程分别进行 Prefill 阶段和 Decode 阶段的单独 profiling：使用 `torch.profiler` 分别抓取两部分的 trace。
- **分析**：合并 Profiler 数据，找出 Top 5 耗时算子（通常为 attention、softmax、matmul 等）；观察 GPU kernel 间隙。
- **产出**：Profiler Trace 报告与 TopK 列表。

#### Week13 Day2: Nsight Systems 流程跟踪

- **操作**：使用 `nsys profile` 抓取完整推理会话的 Timeline（包括 CUDA kernel 和 CPU 调度）。
- **分析**：在 Nsight timeline 中检查 GPU 是否存在空闲时间（Launch Bound vs Memory Bound）；查看数据拷贝（H2D/D2H）与计算是否重叠。
- **产出**：Nsight Timeline 截图和分析笔记。

#### Week13 Day3: 并行流与数据传输

- **操作**：分析 Nsight 报告中的多个 CUDA stream 行为，观察主流和辅流之间的并行情况；检查是否实现了数据传输与计算重叠。
- **分析**：确认是否存在效率低下的串行数据传输；如有，考虑使用异步拷贝或双缓冲优化。
- **产出**：并行流分析文档。

#### Week13 Day4: 专业报告撰写

- **操作**：整理 Profiler 和 Nsight 的发现，形成一份《MiniMind 推理性能剖析报告》。
- **分析**：报告中应包含 Timeline 截图、TopK 算子列表、瓶颈分析（计算受限 vs 内存受限），并提出初步优化建议。
- **产出**：性能剖析报告文档。

#### Week13 Day5: 代码级细节检查

- **操作**：针对发现的瓶颈算子（如过多的小 kernel launch 或大规模数据复制），检查 MiniMind 源码中相关实现是否可优化（例如合并 kernel，减少不必要的张量操作）。
- **分析**：记录潜在改进点，为第 21-22 周的改造做准备。
- **产出**：优化建议清单。

**交付物**：`benchmarks/profile_report.md`，包括 Profiler 和 Nsight 截图、分析结论和优化方向建议。

**验收标准**：能够明确指出推理过程中的主要瓶颈（计算 vs 内存 vs Launch），并给出量化数据和可行的改进思路。

### 第 15-16 周：长上下文与KV Cache优化

**组目标**：验证长上下文场景下的性能瓶颈，深入理解 KV Cache 布局与显存消耗，对模型在实际场景中的表现做压测。

#### Week15 Day1: 长上下文内存测试

- **操作**：固定模型和输入，逐渐增加 Prefill 长度（如从 128 到 2048），记录每种长度下的显存峰值和 Prefill 延迟（首token延迟 TTFT）。
- **分析**：绘制显存 vs 上下文长度的曲线，找出 O(T) 增长的位置；解释显存增长的主要来源。
- **产出**：显存与 TTFT 曲线图。

#### Week15 Day2: 长生成吞吐测试

- **操作**：固定 prompt 长度，设置不同的 `max_new_tokens`（如 100、500、1000），记录 Decode 阶段的整体吞吐（TPS）。
- **分析**：绘制 TPS vs 生成长度的曲线，分析生成长文本时主要受限于哪些因素（如 KV concatenation）。
- **产出**：TPS vs 长度曲线图。

#### Week15 Day3: GQA/MQA 布局对比

- **操作**：测试 MiniMind 在 GQA（Grouped QKV）和 MQA（Multi-Query Attention）两种 KV 布局下的推理性能与显存使用。
- **分析**：比较两种模式下长上下文时的优劣，解释原因。
- **产出**：GQA vs MQA 性能对比报告。

#### Week15 Day4: KV Cache 物理结构图

- **操作**：绘制 MiniMind 使用 Prefill + Decode 时的 KV Cache 物理内存结构图示：按层、按头、按序列组织的逻辑视图。
- **分析**：说明当前 KV Cache 实现如何导致显存增长；对比理论上的分页（PagedAttention）方式。
- **产出**：KV Cache 内存逻辑图。

#### Week15 Day5: 长序列总结

- **操作**：综合以上实验结果，撰写 `long_context.md` 报告。
- **分析**：总结在不同上下文长度下性能和显存的变化，提出 KV Cache 优化的思路（如分块、复用）。
- **产出**：长上下文压测报告。

**交付物**：`benchmarks/long_context.md`，包含显存曲线、TPS 曲线、GQA/MQA 比较和结论图示。

**验收标准**：清楚展示长上下文下显存和性能如何随序列长度变化；解释影响性能的主因并提出可能的优化方案。

### 第 17-18 周：模型量化与格式转化

**组目标**：掌握模型精度压缩技术和多种模型格式的转换，完成端侧部署前的准备和对比测试。

#### Week17 Day1: 准备量化工具

- **操作**：使用 bitsandbytes 或 GPTQ 对 MiniMind 模型进行 8-bit/4-bit 量化转换，生成量化后的模型参数。
- **分析**：记录量化过程参数（对称/非对称量化），观察压缩后模型大小。
- **产出**：量化后模型文件（如 `8bit.pt` 或 `4bit.pt`）。

#### Week17 Day2: 量化性能对比

- **操作**：在小型验证集或任务集上，比较原始 FP16 模型与量化模型的性能：评估 PPL（困惑度）、生成质量和推理速度。
- **分析**：记录精度损失幅度和加速率，分析离群值对量化精度的影响。
- **产出**：PPL 和速度对比表格及示例输出。

#### Week17 Day3: llama.cpp 转换

- **操作**：使用 `convert_hf_to_gguf.py` 脚本将模型转换为 llama.cpp 可用的 GGUF 格式，确保词表等兼容性。
- **分析**：尝试在本地 CPU（或 Low-setup GPU）上使用 llama.cpp 运行量化模型，测试推理功能。
- **产出**：转换脚本 `export_gguf.sh` 及运行日志。

#### Week17 Day4: 端侧部署（MNN）

- **操作**：参考 README，使用 MNN 框架导出模型（4-bit HQQ 量化）并部署到非 NVIDIA 设备（如手机仿真器）。
- **分析**：测试模型在端侧的推理性能（延迟、吞吐）和资源占用（内存、CPU）。
- **产出**：端侧部署脚本（`export_mnn.sh`）和运行结果报告。

#### Week17 Day5: 量化报告撰写

- **操作**：整理量化前后模型在精度、推理速度、模型体积上的对比数据，形成 `quantization.md`。
- **产出**：量化对比报告文档。

**交付物**：`benchmarks/quantization.md`（包括 PPL 对比、性能测试截图）、导出脚本（如 `export_gguf.sh`、`export_mnn.sh`）。

**验收标准**：量化前后模型在 PPL 和 TPS 上的差异清晰量化；成功在目标平台（CPU/GPU/移动端）加载运行量化模型，文档齐全。

### 第 19-20 周：高效推理与前沿 RL 算法

**组目标**：学习使用高级推理框架（如 vLLM）进行高并发推理，并探索最新的强化学习算法（如 SPO）。

#### Week19 Day1: vLLM 服务化启动

- **操作**：使用 MiniMind 仓库提供的命令启动 vLLM 服务。
- **分析**：确保服务能够接收 OpenAI API 兼容请求；观察 vLLM 的 PagedAttention 对显存管理的优化。
- **产出**：vLLM 服务端运行日志。

#### Week19 Day2: SPO (Single-stream Policy Optimization) 探索

- **操作**：阅读 `trainer/train_spo.py`，了解 SPO 如何解决 GRPO 的“退化组（Degenerate Groups）”问题。
- **分析**：理解 SPO 的单流设计及其自适应 Baseline 机制；对比 SPO 与 GRPO 的损失函数差异。
- **产出**：SPO 算法原理笔记。

#### Week19 Day3: 并发压测与对比分析

- **操作**：使用压测工具模拟多并发环境，对比 vLLM 与原生 FastAPI 服务的 TPOT 和延迟。
- **分析**：评估并行处理带来的性能提升；验证 vLLM 在长序列高并发下的稳定性。
- **产出**：并发性能对比报告。

#### Week19 Day4: SPO 训练实验

- **操作**：运行小规模 SPO 训练，观察 Reward 曲线的变化。
- **分析**：分析 Reward 波动与 PPO/GRPO 的差异，记录训练过程中的异常点。
- **产出**：SPO 训练曲线图。

#### Week19 Day5: 环境稳定性测试

- **操作**：尝试在本地多卡或不同模型大小下重复测试，观察是否稳定；捕获异常和日志。
- **分析**：确认模型在高并发下无崩溃；记录日志作为报告附录。
- **产出**：补充实验日志与最终报告。

**交付物**：`benchmarks/vllm_serving.md`（并发吞吐与延迟分析）、压测脚本、服务化相关文档。

**验收标准**：成功搭建并测试 vLLM 服务，数据清晰展示并发并行下的吞吐提升；服务稳定运行，能够复现并行推理结果。

### 第 21-22 周：推理模型 (Reasoning) 与优化

**组目标**：掌握 Reasoning 模型的训练原理，复现 MiniMind-Reason 的思考链机制，并进行量化性能优化。

#### Week21 Day1: Reasoning 蒸馏原理

- **操作**：阅读 `trainer/train_distill_reason.py`，理解如何通过蒸馏获取大模型的思考能力。
- **分析**：重点研究 `<think>` 和 `<answer>` 标签的解析逻辑，以及如何通过 Loss Mask 惩罚项强制模型符合模板规范。
- **产出**：Reasoning 蒸馏技术分析报告。

#### Week21 Day2-3: 实施 Reasoning 训练

- **操作**：使用 `r1_mix_1024.jsonl` 数据集进行 Reasoning 蒸馏训练。
- **分析**：观察模型在训练过程中是否逐渐学会“思考”；检查模型在推理时是否会出现逻辑混乱或标签脱离。
- **产出**：Reasoning 模型训练日志与样本输出。

#### Week21 Day4: 优化改造 - 降低奖励稀疏

- **操作**：针对 RL 训练中的奖励稀疏问题，尝试混合奖励函数（Rule-based + Model-based）。
- **分析**：在 `trainer/train_grpo.py` 中修改奖励计算逻辑，观察其对模型收敛速度的影响。
- **产出**：优化后的奖励函数代码与对比结果。

#### Week21 Day5: 最终基准测试

- **操作**：对比普通 SFT 模型与 Reasoning 模型在逻辑推理题（如数学、逻辑）上的表现。
- **分析**：验证“思考”过程是否真的提升了答案的准确率。
- **产出**：Reasoning vs Base 性能对比表。

**交付物**：实验记录-改造.md（说明改动点、效果对比）、可复现脚本或 PR 代码。

**验收标准**：改造带来可量化提升（如 TPS 提高 ≥5%、显存降低 ≥10% 或更稳定的训练）；提供完整的性能对比数据和复现命令；若是 PR，应符合项目标准并附有实验依据。

### 第 23-24 周：开源贡献与总结

**组目标**：将学习成果与项目闭环，通过实际的 Issue/PR 贡献给社区，总结完整的学习闭环。

#### Week23 Day1: 提出 Issue

- **操作**：复现并验证一个可改进的问题或缺陷，按照社区要求填写 Issue 模板，提供复现步骤、日志、环境等信息。
- **产出**：MiniMind 仓库 issue 页面截图或链接。

#### Week23 Day2-3: 提交修复或功能改进 PR

- **操作**：根据 Issue 编写修复代码或功能完善（文档、脚本、单元测试等），在项目中提交 PR。
- **分析**：确保 PR 描述清晰、变动小且目标明确；附上对应的测试结果。
- **产出**：PR 链接和变更说明。

#### Week23 Day4: 社区复盘与总结

- **操作**：整理本次学习路线的所有产出（报告、代码、数据），撰写总结文档。
- **产出**：学习总结或博客草稿，涵盖主要收获和未来工作建议。

#### Week23 Day5: 毕业设计准备

- **操作**：整理论文或项目报告的最终骨架和内容概要，准备展示用的材料（PPT、视频或 Demo）。
- **产出**：毕业设计提纲。

**交付物**：至少 1 个 GitHub Issue、1 个 PR（即使是文档完善也可）；完整的项目复现仓库，包括 README、实验数据和分析报告。

**验收标准**：Issue/PR 被接受并合并（或至少通过 review）；可以用标准化方式（Markdown、表格、图表）全面展示改进效果；所交付材料满足毕业设计要求。

## 毕业设计与最终输出

完成以上学习后，建议最终输出以下成果作为你的核心亮点和毕业项目内容：

1. **深度性能报告**：基于 Nsight Systems 或 torch.profiler 的全面性能剖析报告，展示如何识别模型瓶颈并通过算子优化或缓存优化提升吞吐率。
2. **自定义高性能算子**：基于 Triton 实现的高性能算子（如 Norm、Attention Kernel）代码，并集成到模型中进行验证。
3. **完整的压测数据**：包括不同并发数、不同量化精度下的推理延迟/吞吐对比报告（如 Locust 压测数据）。
4. **MiniMind 复现仓库**：包含所有实验代码、脚本、注释和数据的仓库，配备清晰的 README、结构化的 `benchmarks/` 和 `experiments/` 目录。
5. **开源贡献记录**：提交的 Issue 和 PR 链接，显示你对 MiniMind 项目的贡献与改进。

这些成果可作为简历中的实践项目展示，体现你在底层优化和系统工程方面的实战能力。

## 附录：工具链准备、资料推荐与实验模板

### 必备工具：

- **代码阅读**：VS Code + Sourcetrail 或 Cursor（AI 辅助）。
- **性能分析**：PyTorch 内置 `torch.profiler`；NVIDIA Nsight Systems (nsys)；Python 的 py-spy。
- **训练监控**：SwanLab（首选，兼容 W&B）、TensorBoard。
- **算子开发**：OpenAI Triton。
- **模型可视化**：Netron。
- **推理与部署**：Ollama, llama.cpp, vLLM, MNN。
- **压测工具**：Locust, wrk。

### 推荐资料：

- MiniMind 官方仓库 README（包含最新的 MiniMind2 与 Reasoning 模型说明）。
- DeepSeek-R1 论文：理解冷启动与 GRPO 强化学习。
- SPO 算法论文 (腾讯)：了解单流策略优化。
- YaRN 论文：位置编码的长度外推技术。
- MNN 官方文档：移动端推理优化。

### 实验记录模板建议：

使用 Markdown 格式记录实验（如 `experiments/` 目录），并用表格整理超参与指标。示例模板：

| 实验编号 | 修改点／超参 | Speed (tokens/s) | PPL | 显存峰值 | 备注 |
|---------|------------|-----------------|-----|---------|------|
| Exp-01 | Base (FP16, bs=8) | 1234 | 20.5 | 6.7GB | 基线 |
| Exp-02 | +Triton RMSNorm | 1460 | 20.5 | 6.5GB | 加速 ~18% |
| Exp-03 | +AMP（Mixed Precision） | 2100 | 20.5 | 4.0GB | 加速~70%，显存减小 |

同时记录环境信息（GPU 型号、显存、CUDA 版本）、命令行和观测日志，保持实验结果可复现。每次实验结束及时总结结论，形成报告文档。
